{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REGULARIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create two prediction models both for solar energy output and wind energy output. In order to predict these outputs we want to build a model that selects the best possible predictors maximizing the feature significance, avoiding colinearity, ensuring sparisty, considering the best feature transformations... To do so we will apply different models like Lasso, and Ridge and then we can apply Holistic Regression to see how the model is improved by it. We will run all of these models by all predictors of solar and energy output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, Tables, LinearAlgebra, Random, Gurobi, JuMP, Statistics, DataFrames\n",
    "#read train and validation data and split it into X and y\n",
    "X_train_solar=Matrix(DataFrame(CSV.File(\"X_train_solar.csv\")))\n",
    "y_train_solar=Matrix(DataFrame(CSV.File(\"y_train_solar.csv\")))\n",
    "X_train_wind=Matrix(DataFrame(CSV.File(\"X_train_wind.csv\")))\n",
    "y_train_wind=Matrix(DataFrame(CSV.File(\"y_train_wind.csv\")))\n",
    "\n",
    "X_valid_solar=Matrix(DataFrame(CSV.File(\"X_valid_solar.csv\")))\n",
    "y_valid_solar=Matrix(DataFrame(CSV.File(\"y_valid_solar.csv\")))\n",
    "X_valid_wind=Matrix(DataFrame(CSV.File(\"X_valid_wind.csv\")))\n",
    "y_valid_wind=Matrix(DataFrame(CSV.File(\"y_valid_wind.csv\")));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lasso (generic function with 2 methods)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function lasso(X,y,lambda=0.25)\n",
    "    \n",
    "    #Build model\n",
    "    model = Model(Gurobi.Optimizer)#we have defined the model, pass Gurobi optimizer into the model\n",
    "    set_optimizer_attribute(model,\"OutputFlag\",0)\n",
    "    \n",
    "    #Insert variables\n",
    "    n, p = size(X)\n",
    "    \n",
    "    @variable(model, beta[j=1:p])\n",
    "    @variable(model, beta_abs[j=1:p])\n",
    "    \n",
    "    \n",
    "    #Insert constraints\n",
    "\n",
    "    @constraint(model, beta_abs .>= beta) #put the dot is like doing the loop over all j\n",
    "    @constraint(model, beta_abs .>= -beta)\n",
    "    \n",
    "    \n",
    "    #sum((y-X*beta).^2)) = sum((y[i] - sum(X[i,j]*beta[j]) for j=1:p)^2 for i=1:n)\n",
    "    \n",
    "    #Insert objective\n",
    "    @objective(model, Min, sum((y-X*beta).^2) + lambda*sum(beta_abs))\n",
    "    \n",
    "    \n",
    "    # Optimize\n",
    "    optimize!(model)\n",
    "    \n",
    "    # Return estimated betas\n",
    "    return (value.(beta))\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mse (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mse(X,y, beta)\n",
    "    return sum((y-X*beta).^2)/length(y)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "correlation (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function correlation(X,p)\n",
    "    correlation_matrix = Statistics.cor(X) #compute corr matrix\n",
    "    n,m = size(correlation_matrix) #set sizes\n",
    "    correlated_pairs=[] #empty list to store correlated pairs\n",
    "    for i=1:n #for all features\n",
    "        for j=i+1:m \n",
    "            if abs(correlation_matrix[i,j])>p #if the abs value of the corr is higher than p\n",
    "                push!(correlated_pairs, (i,j)) #append pair to list of correlated pairs\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return correlated_pairs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformation (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build transformation function\n",
    "function transformation(X)\n",
    "    X_old=DataFrame(X, :auto) #define X as a df\n",
    "    X_new=DataFrame() #new empty df \n",
    "    n,p=size(X_old)\n",
    "    e=1\n",
    "    for i=1:p #for each feature in X add 4 transformations\n",
    "        X_new[!, \"X$i\"]=X_old[:,i] #transformation 1\n",
    "        X_new[!, \"Sqrt$i\"]=X_old[:,i].^2 #transformation 2\n",
    "        X_new[!, \"Abs$i\"]=sqrt.(abs.(X_old[:,i])) #transformation 3\n",
    "        X_new[!, \"Log$i\"]=log.(abs.(X_old[:,i]).+e) #transformation 4\n",
    "    end\n",
    "    return(X_new) #we return a new df with all transformations, it will have size nxp*4\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "holistic_regression (generic function with 5 methods)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function holistic_regression(X,y,lambda=0.25, per=0.6, M=50, k=10) #add parameter per\n",
    "    \n",
    "    #Call functions\n",
    "    X_new=Matrix(transformation(X)) #call function with all transformations of X\n",
    "    HC = correlation(X_new, per) #call correlation function to compute hc_pairs\n",
    "    \n",
    "    #Set sizes\n",
    "    n,p_new=size(X_new)\n",
    "    \n",
    "    #Build model\n",
    "    model = Model(Gurobi.Optimizer, NonConvex = 2)#we have defined the model, pass Gurobi optimizer into the model\n",
    "    #model = Model(with_optimizer(Gurobi.Optimizer, NonConvex = 2))\n",
    "    set_optimizer_attribute(model,\"OutputFlag\",0)\n",
    "    \n",
    "    #Insert variables\n",
    "    @variable(model, beta[1:p_new])\n",
    "    @variable(model, beta_abs[1:p_new])\n",
    "    @variable(model, z[1:p_new], Bin) #we add a binary variable\n",
    "    \n",
    "\n",
    "    #Insert constraints\n",
    "    @constraint(model, beta_abs .>= beta) #put the dot is like doing the loop over all j\n",
    "    @constraint(model, beta_abs .>= -beta)\n",
    "    \n",
    "        \n",
    "    #sparsity constraint: over all 60 features (including transformations) \n",
    "    @constraint(model, -M*z .<= beta)\n",
    "    @constraint(model, beta .<= M*z)\n",
    "    @constraint(model, sum(z) <= k) \n",
    "    \n",
    "    #constraint on Transformation: from the 4 transformations per each feature we only select one\n",
    "    for i=1:4:p_new\n",
    "        #for j=i:i+3 #for every 4 transformations\n",
    "        @constraint(model, sum(z[i:i+3])<=1)\n",
    "        #end\n",
    "    end #we get a vector with 15 features\n",
    "    \n",
    "    #constraint on HC pairs once we have selected 15 features \n",
    "    for (i,j) in HC\n",
    "        @constraint(model, z[i] + z[j] <= 1)\n",
    "    end #we can only take one of the pairs of correlated pairs\n",
    "    #@constraint(model, sum(z[i])<=k) #ensure that the model has at most 8 features\n",
    "    \n",
    "        \n",
    "    #Insert objective\n",
    "    @objective(model, Min, sum((y-X_new*beta).^2) + lambda*sum(beta_abs))\n",
    "    \n",
    "    \n",
    "    # Optimize\n",
    "    optimize!(model)\n",
    "    \n",
    "    # Return estimated betas\n",
    "    return (value.(beta))\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOLAR ENERGY OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2023-08-19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26-element Vector{Float64}:\n",
       "     4.2093647114128725\n",
       "    -1.5309979769072977\n",
       "    -0.8824028062001327\n",
       "     1.9116802490399556\n",
       "   216.52631332891622\n",
       "   -12.49098360321547\n",
       "     7.631817286371418\n",
       "    10.277016991626004\n",
       "     0.5859704225440101\n",
       "     0.11911001017780573\n",
       "     3.824568986827269\n",
       "     0.10472846328274894\n",
       "    -3.2765141766725527\n",
       "     0.42268676075881506\n",
       "     5.486719230074171\n",
       "   -40.48963755673621\n",
       "     3.226686082766982\n",
       "    -2.064111695818705\n",
       "   -13.16697989755074\n",
       "    53.64545205181411\n",
       "   -10.82816662953645\n",
       "     1.705722438924721e-6\n",
       " -1223.350040953427\n",
       "     9.800267876089153e-11\n",
       "     1.7057225056152977e-6\n",
       "   -10.82816662953645"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_lasso=lasso(X_train_solar,y_train_solar,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87533.0624297519"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(X_valid_solar, y_valid_solar, beta_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13-element Vector{Any}:\n",
       " (1, 2)\n",
       " (1, 3)\n",
       " (2, 3)\n",
       " (6, 19)\n",
       " (6, 23)\n",
       " (6, 24)\n",
       " (14, 15)\n",
       " (17, 18)\n",
       " (19, 23)\n",
       " (19, 24)\n",
       " (21, 26)\n",
       " (22, 25)\n",
       " (23, 24)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation(X_train_solar,0.6) #correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>5 rows × 104 columns (omitted printing of 95 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>X1</th><th>Sqrt1</th><th>Abs1</th><th>Log1</th><th>X2</th><th>Sqrt2</th><th>Abs2</th><th>Log2</th><th>X3</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>32.4</td><td>1049.76</td><td>5.6921</td><td>3.50856</td><td>29.7</td><td>882.09</td><td>5.44977</td><td>3.42426</td><td>24.0</td></tr><tr><th>2</th><td>32.5</td><td>1056.25</td><td>5.70088</td><td>3.51155</td><td>32.5</td><td>1056.25</td><td>5.70088</td><td>3.51155</td><td>24.1</td></tr><tr><th>3</th><td>31.6</td><td>998.56</td><td>5.62139</td><td>3.48431</td><td>28.3</td><td>800.89</td><td>5.31977</td><td>3.37759</td><td>24.2</td></tr><tr><th>4</th><td>31.6</td><td>998.56</td><td>5.62139</td><td>3.48431</td><td>26.8</td><td>718.24</td><td>5.17687</td><td>3.32504</td><td>25.1</td></tr><tr><th>5</th><td>31.8</td><td>1011.24</td><td>5.63915</td><td>3.49043</td><td>27.2</td><td>739.84</td><td>5.21536</td><td>3.33932</td><td>25.2</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& X1 & Sqrt1 & Abs1 & Log1 & X2 & Sqrt2 & Abs2 & Log2 & X3 & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 32.4 & 1049.76 & 5.6921 & 3.50856 & 29.7 & 882.09 & 5.44977 & 3.42426 & 24.0 & $\\dots$ \\\\\n",
       "\t2 & 32.5 & 1056.25 & 5.70088 & 3.51155 & 32.5 & 1056.25 & 5.70088 & 3.51155 & 24.1 & $\\dots$ \\\\\n",
       "\t3 & 31.6 & 998.56 & 5.62139 & 3.48431 & 28.3 & 800.89 & 5.31977 & 3.37759 & 24.2 & $\\dots$ \\\\\n",
       "\t4 & 31.6 & 998.56 & 5.62139 & 3.48431 & 26.8 & 718.24 & 5.17687 & 3.32504 & 25.1 & $\\dots$ \\\\\n",
       "\t5 & 31.8 & 1011.24 & 5.63915 & 3.49043 & 27.2 & 739.84 & 5.21536 & 3.33932 & 25.2 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5×104 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m X1      \u001b[0m\u001b[1m Sqrt1   \u001b[0m\u001b[1m Abs1    \u001b[0m\u001b[1m Log1    \u001b[0m\u001b[1m X2      \u001b[0m\u001b[1m Sqrt2   \u001b[0m\u001b[1m Abs2    \u001b[0m\u001b[1m Log2    \u001b[0m\u001b[1m\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │    32.4  1049.76  5.6921   3.50856     29.7   882.09  5.44977  3.42426  ⋯\n",
       "   2 │    32.5  1056.25  5.70088  3.51155     32.5  1056.25  5.70088  3.51155\n",
       "   3 │    31.6   998.56  5.62139  3.48431     28.3   800.89  5.31977  3.37759\n",
       "   4 │    31.6   998.56  5.62139  3.48431     26.8   718.24  5.17687  3.32504\n",
       "   5 │    31.8  1011.24  5.63915  3.49043     27.2   739.84  5.21536  3.33932  ⋯\n",
       "\u001b[36m                                                              96 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(transformation(X_train_solar), 5) #all transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching Model(::Type{Gurobi.Optimizer}; NonConvex=2)\n\u001b[0mClosest candidates are:\n\u001b[0m  Model(::Any; add_bridges) at /Users/iai/builds/e7x1Q22r/0/InterpretableAI/SystemImage/SysImgBuilder/.julia/packages/JuMP/60Bnj/src/JuMP.jl:219\u001b[91m got unsupported keyword argument \"NonConvex\"\u001b[39m\n\u001b[0m  Model(::Any, \u001b[91m::Any\u001b[39m, \u001b[91m::Any\u001b[39m, \u001b[91m::Any\u001b[39m, \u001b[91m::Any\u001b[39m, \u001b[91m::Any\u001b[39m, \u001b[91m::Any\u001b[39m, \u001b[91m::Any\u001b[39m, \u001b[91m::Any\u001b[39m, \u001b[91m::Any\u001b[39m) at /Users/iai/builds/e7x1Q22r/0/InterpretableAI/SystemImage/SysImgBuilder/.julia/packages/JuMP/60Bnj/src/JuMP.jl:134\u001b[91m got unsupported keyword argument \"NonConvex\"\u001b[39m\n\u001b[0m  Model() at /Users/iai/builds/e7x1Q22r/0/InterpretableAI/SystemImage/SysImgBuilder/.julia/packages/JuMP/60Bnj/src/JuMP.jl:189\u001b[91m got unsupported keyword argument \"NonConvex\"\u001b[39m\n\u001b[0m  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching Model(::Type{Gurobi.Optimizer}; NonConvex=2)\n\u001b[0mClosest candidates are:\n\u001b[0m  Model(::Any; add_bridges) at /Users/iai/builds/e7x1Q22r/0/InterpretableAI/SystemImage/SysImgBuilder/.julia/packages/JuMP/60Bnj/src/JuMP.jl:219\u001b[91m got unsupported keyword argument \"NonConvex\"\u001b[39m\n\u001b[0m  Model(::Any, \u001b[91m::Any\u001b[39m, \u001b[91m::Any\u001b[39m, \u001b[91m::Any\u001b[39m, \u001b[91m::Any\u001b[39m, \u001b[91m::Any\u001b[39m, \u001b[91m::Any\u001b[39m, \u001b[91m::Any\u001b[39m, \u001b[91m::Any\u001b[39m, \u001b[91m::Any\u001b[39m) at /Users/iai/builds/e7x1Q22r/0/InterpretableAI/SystemImage/SysImgBuilder/.julia/packages/JuMP/60Bnj/src/JuMP.jl:134\u001b[91m got unsupported keyword argument \"NonConvex\"\u001b[39m\n\u001b[0m  Model() at /Users/iai/builds/e7x1Q22r/0/InterpretableAI/SystemImage/SysImgBuilder/.julia/packages/JuMP/60Bnj/src/JuMP.jl:189\u001b[91m got unsupported keyword argument \"NonConvex\"\u001b[39m\n\u001b[0m  ...",
      "",
      "Stacktrace:",
      " [1] kwerr(::NamedTuple{(:NonConvex,), Tuple{Int64}}, ::Type, ::Type)",
      "   @ Base ./error.jl:165",
      " [2] holistic_regression(X::Matrix{Float64}, y::Matrix{Float64}, lambda::Float64, per::Float64, M::Int64, k::Int64)",
      "   @ Main ./In[47]:11",
      " [3] holistic_regression(X::Matrix{Float64}, y::Matrix{Float64})",
      "   @ Main ./In[47]:4",
      " [4] top-level scope",
      "   @ In[48]:1",
      " [5] eval",
      "   @ ./boot.jl:368 [inlined]",
      " [6] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1428"
     ]
    }
   ],
   "source": [
    "beta_opt=holistic_regression(X_train_solar, y_train_solar) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
