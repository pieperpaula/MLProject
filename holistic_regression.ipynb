{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REGULARIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create two prediction models both for solar energy output and wind energy output. In order to predict these outputs we want to build a model that selects the best possible predictors maximizing the feature significance, avoiding colinearity, ensuring sparisty, considering the best feature transformations... To do so we will apply different models like Lasso, and Ridge and then we can apply Holistic Regression to see how the model is improved by it. We will run all of these models by all predictors of solar and energy output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. SOLAR ENERGY OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, Tables, LinearAlgebra, Random, Gurobi, JuMP, Statistics, DataFrames\n",
    "#read train data and split it into X and y\n",
    "X_train_solar=\n",
    "y_train_solar=\n",
    "X_train_energy=\n",
    "y_train_energy=\n",
    "\n",
    "X_valid_solar=\n",
    "y_valid_solar=\n",
    "X_valid_energy=\n",
    "y_valid_energy="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function lasso(X,y,lambda=0.25)\n",
    "    \n",
    "    #Build model\n",
    "    model = Model(Gurobi.Optimizer)#we have defined the model, pass Gurobi optimizer into the model\n",
    "    set_optimizer_attribute(model,\"OutputFlag\",0)\n",
    "    \n",
    "    #Insert variables\n",
    "    n, p = size(X)\n",
    "    \n",
    "    @variable(model, beta[j=1:p])\n",
    "    @variable(model, beta_abs[j=1:p])\n",
    "    \n",
    "    \n",
    "    #Insert constraints\n",
    "\n",
    "    @constraint(model, beta_abs .>= beta) #put the dot is like doing the loop over all j\n",
    "    @constraint(model, beta_abs .>= -beta)\n",
    "    \n",
    "    \n",
    "    #sum((y-X*beta).^2)) = sum((y[i] - sum(X[i,j]*beta[j]) for j=1:p)^2 for i=1:n)\n",
    "    \n",
    "    #Insert objective\n",
    "    @objective(model, Min, sum((y-X*beta).^2) + lambda*sum(beta_abs))\n",
    "    \n",
    "    \n",
    "    # Optimize\n",
    "    optimize!(model)\n",
    "    \n",
    "    # Return estimated betas\n",
    "    return (value.(beta))\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mse(X,y, beta)\n",
    "    return sum((y-X*beta).^2)/length(y)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function correlation(X,p)\n",
    "    correlation_matrix = Statistics.cor(X) #compute corr matrix\n",
    "    n,m = size(correlation_matrix) #set sizes\n",
    "    correlated_pairs=[] #empty list to store correlated pairs\n",
    "    for i=1:n #for all features\n",
    "        for j=i+1:m \n",
    "            if abs(correlation_matrix[i,j])>p #if the abs value of the corr is higher than p\n",
    "                push!(correlated_pairs, (i,j)) #append pair to list of correlated pairs\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return correlated_pairs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build transformation function\n",
    "function transformation(X)\n",
    "    X_old=DataFrame(X, :auto) #define X as a df\n",
    "    X_new=DataFrame() #new empty df \n",
    "    n,p=size(X_old)\n",
    "    e=1\n",
    "    for i=1:p #for each feature in X add 4 transformations\n",
    "        X_new[!, \"X$i\"]=X_old[:,i] #transformation 1\n",
    "        X_new[!, \"Sqrt$i\"]=X_old[:,i].^2 #transformation 2\n",
    "        X_new[!, \"Abs$i\"]=sqrt.(abs.(X_old[:,i])) #transformation 3\n",
    "        X_new[!, \"Log$i\"]=log.(abs.(X_old[:,i]).+e) #transformation 4\n",
    "    end\n",
    "    return(X_new) #we return a new df with all transformations, it will have size nxp*4\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function holistic_regression(X,y,lambda=0.25, per=0.5, M=50, k=8) #add parameter per\n",
    "    \n",
    "    #Call functions\n",
    "    X_new=Matrix(transformation(X)) #call function with all transformations of X\n",
    "    HC = correlation(X_new, per) #call correlation function to compute hc_pairs\n",
    "    \n",
    "    #Set sizes\n",
    "    n,p_new=size(X_new)\n",
    "    \n",
    "    #Build model\n",
    "    model = Model(Gurobi.Optimizer)#we have defined the model, pass Gurobi optimizer into the model\n",
    "    set_optimizer_attribute(model,\"OutputFlag\",0)\n",
    "    \n",
    "    #Insert variables\n",
    "    @variable(model, beta[1:p_new])\n",
    "    @variable(model, beta_abs[1:p_new])\n",
    "    @variable(model, z[1:p_new], Bin) #we add a binary variable\n",
    "    \n",
    "\n",
    "    #Insert constraints\n",
    "    @constraint(model, beta_abs .>= beta) #put the dot is like doing the loop over all j\n",
    "    @constraint(model, beta_abs .>= -beta)\n",
    "    \n",
    "        \n",
    "    #sparsity constraint: over all 60 features (including transformations) \n",
    "    @constraint(model, -M*z .<= beta)\n",
    "    @constraint(model, beta .<= M*z)\n",
    "    @constraint(model, sum(z) <= k) \n",
    "    \n",
    "    #constraint on Transformation: from the 4 transformations per each feature we only select one\n",
    "    for i=1:4:p_new\n",
    "        #for j=i:i+3 #for every 4 transformations\n",
    "        @constraint(model, sum(z[i:i+3])<=1)\n",
    "        #end\n",
    "    end #we get a vector with 15 features\n",
    "    \n",
    "    #constraint on HC pairs once we have selected 15 features \n",
    "    for (i,j) in HC\n",
    "        @constraint(model, z[i] + z[j] <= 1)\n",
    "    end #we can only take one of the pairs of correlated pairs\n",
    "    #@constraint(model, sum(z[i])<=k) #ensure that the model has at most 8 features\n",
    "    \n",
    "        \n",
    "    #Insert objective\n",
    "    @objective(model, Min, sum((y-X_new*beta).^2) + lambda*sum(beta_abs))\n",
    "    \n",
    "    \n",
    "    # Optimize\n",
    "    optimize!(model)\n",
    "    \n",
    "    # Return estimated betas\n",
    "    return (value.(beta))\n",
    "    \n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
